{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Style Transfer\n",
    "\n",
    "Neural style transfer mit modernem TensorFlow/Keras.\n",
    "\n",
    "Verwendung:\n",
    "- Passe die Pfade zu deinen Bildern an (base_image_path, style_reference_image_path)\n",
    "- Führe das Skript aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bildgröße: 400x600\n",
      "Model loaded.\n",
      "Extrahiere Features...\n",
      "Style layers: 5\n",
      "Content layers: 1\n",
      "\n",
      "Starte Style Transfer...\n",
      "\n",
      "=== Iteration 1/3 ===\n",
      "Step   0: Loss=  1.7929e+04 (style=1.7929e+04, content=0.0000e+00, tv=1.8798e-05)\n",
      "Step  20: Loss=  9.5235e+03 (style=9.5235e+03, content=5.8399e-06, tv=1.8862e-05)\n",
      "Step  40: Loss=  6.0258e+03 (style=6.0258e+03, content=1.8774e-05, tv=1.9163e-05)\n",
      "Step  60: Loss=  4.9229e+03 (style=4.9229e+03, content=2.8000e-05, tv=1.9536e-05)\n",
      "Step  80: Loss=  4.3795e+03 (style=4.3795e+03, content=3.3211e-05, tv=1.9846e-05)\n",
      "✓ Image saved as result_at_iteration_1.png\n",
      "✓ Iteration completed in 119.3s\n",
      "\n",
      "=== Iteration 2/3 ===\n",
      "Step   0: Loss=  3.9367e+03 (style=3.9367e+03, content=3.6046e-05, tv=2.0064e-05)\n",
      "Step  20: Loss=  3.6147e+03 (style=3.6147e+03, content=3.7695e-05, tv=2.0208e-05)\n",
      "Step  40: Loss=  3.2671e+03 (style=3.2671e+03, content=3.8952e-05, tv=2.0297e-05)\n",
      "Step  60: Loss=  2.8224e+03 (style=2.8224e+03, content=4.0298e-05, tv=2.0342e-05)\n",
      "Step  80: Loss=  2.4016e+03 (style=2.4016e+03, content=4.1763e-05, tv=2.0354e-05)\n",
      "✓ Image saved as result_at_iteration_2.png\n",
      "✓ Iteration completed in 139.5s\n",
      "\n",
      "=== Iteration 3/3 ===\n",
      "Step   0: Loss=  2.0898e+03 (style=2.0898e+03, content=4.3218e-05, tv=2.0342e-05)\n",
      "Step  20: Loss=  1.8634e+03 (style=1.8634e+03, content=4.4503e-05, tv=2.0316e-05)\n",
      "Step  40: Loss=  1.6754e+03 (style=1.6754e+03, content=4.5655e-05, tv=2.0287e-05)\n",
      "Step  60: Loss=  1.5268e+03 (style=1.5268e+03, content=4.6643e-05, tv=2.0264e-05)\n",
      "Step  80: Loss=  1.4184e+03 (style=1.4184e+03, content=4.7442e-05, tv=2.0246e-05)\n",
      "✓ Image saved as result_at_iteration_3.png\n",
      "✓ Iteration completed in 138.8s\n",
      "\n",
      "✓ Style Transfer abgeschlossen!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import vgg19\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, save_img\n",
    "from PIL import Image\n",
    "\n",
    "# Konfiguration\n",
    "base_image_path = \"bild.jpg\"\n",
    "style_reference_image_path = \"style.jpg\"\n",
    "result_prefix = \"result_\"\n",
    "iterations = 3\n",
    "\n",
    "# Gewichtungen der verschiedenen Loss-Komponenten\n",
    "total_variation_weight = 1e-6\n",
    "style_weight = 2e-6\n",
    "content_weight = 2.5e-8\n",
    "\n",
    "# Dimensionen des generierten Bildes\n",
    "width, height = load_img(base_image_path).size\n",
    "img_nrows = 400\n",
    "img_ncols = int(width * img_nrows / height)\n",
    "\n",
    "print(f\"Bildgröße: {img_nrows}x{img_ncols}\")\n",
    "\n",
    "# Hilfsfunktionen\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Lädt und preprocessed ein Bild für VGG19.\"\"\"\n",
    "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "\n",
    "def deprocess_image(x):\n",
    "    \"\"\"Konvertiert einen Tensor zurück in ein gültiges Bild.\"\"\"\n",
    "    x = x.numpy()\n",
    "    x = x.reshape((img_nrows, img_ncols, 3))\n",
    "    # Entferne Zero-Center durch Mean Pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def gram_matrix(x):\n",
    "    \"\"\"Berechnet die Gram-Matrix eines Feature-Tensors.\"\"\"\n",
    "    # x hat shape (batch, height, width, channels)\n",
    "    result = tf.linalg.einsum('bijc,bijd->bcd', x, x)\n",
    "    input_shape = tf.shape(x)\n",
    "    num_locations = tf.cast(input_shape[1] * input_shape[2], tf.float32)\n",
    "    return result / num_locations\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Erstellt das VGG19 Feature-Extraction-Modell.\"\"\"\n",
    "    vgg = vgg19.VGG19(include_top=False, weights='imagenet')\n",
    "    vgg.trainable = False\n",
    "    \n",
    "    # Layer für Style und Content\n",
    "    style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
    "    content_layers = ['block5_conv2']\n",
    "    \n",
    "    outputs = [vgg.get_layer(name).output for name in style_layers]\n",
    "    outputs += [vgg.get_layer(name).output for name in content_layers]\n",
    "    \n",
    "    model = keras.Model([vgg.input], outputs)\n",
    "    return model, len(style_layers), len(content_layers)\n",
    "\n",
    "def style_content_loss(outputs, style_targets, content_targets, num_style_layers):\n",
    "    \"\"\"Berechnet Style und Content Loss.\"\"\"\n",
    "    style_outputs = outputs[:num_style_layers]\n",
    "    content_outputs = outputs[num_style_layers:]\n",
    "    \n",
    "    # Style Loss\n",
    "    style_loss = tf.add_n([tf.reduce_mean((style_outputs[i] - style_targets[i])**2) \n",
    "                           for i in range(num_style_layers)])\n",
    "    style_loss *= style_weight / num_style_layers\n",
    "    \n",
    "    # Content Loss\n",
    "    content_loss = tf.add_n([tf.reduce_mean((content_outputs[i] - content_targets[i])**2) \n",
    "                             for i in range(len(content_targets))])\n",
    "    content_loss *= content_weight / len(content_targets)\n",
    "    \n",
    "    return style_loss, content_loss\n",
    "\n",
    "def total_variation_loss(image):\n",
    "    \"\"\"Total Variation Loss für lokale Kohärenz.\"\"\"\n",
    "    x_deltas = image[:, :, 1:, :] - image[:, :, :-1, :]\n",
    "    y_deltas = image[:, 1:, :, :] - image[:, :-1, :, :]\n",
    "    return tf.reduce_mean(tf.abs(x_deltas)) + tf.reduce_mean(tf.abs(y_deltas))\n",
    "\n",
    "# Erstelle Modell\n",
    "model, num_style_layers, num_content_layers = get_model()\n",
    "print('Model loaded.')\n",
    "\n",
    "# Lade und verarbeite Bilder\n",
    "content_image = preprocess_image(base_image_path)\n",
    "style_image = preprocess_image(style_reference_image_path)\n",
    "\n",
    "# Extrahiere Target-Features\n",
    "print(\"Extrahiere Features...\")\n",
    "style_outputs = model(style_image)\n",
    "content_outputs = model(content_image)\n",
    "\n",
    "# Berechne Gram-Matrizen für Style\n",
    "style_targets = [gram_matrix(style_output) for style_output in style_outputs[:num_style_layers]]\n",
    "content_targets = content_outputs[num_style_layers:]\n",
    "\n",
    "print(f\"Style layers: {num_style_layers}\")\n",
    "print(f\"Content layers: {num_content_layers}\")\n",
    "\n",
    "# Initialisiere das generierte Bild mit dem Content-Bild\n",
    "generated_image = tf.Variable(content_image, dtype=tf.float32)\n",
    "\n",
    "# Optimizer\n",
    "opt = tf.optimizers.Adam(learning_rate=5.0, beta_1=0.99, epsilon=1e-1)\n",
    "\n",
    "@tf.function()\n",
    "def train_step(image):\n",
    "    \"\"\"Ein Trainingsschritt.\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(image)\n",
    "        \n",
    "        # Berechne Gram-Matrizen für generiertes Bild\n",
    "        style_outputs = [gram_matrix(output) for output in outputs[:num_style_layers]]\n",
    "        \n",
    "        # Berechne Losses\n",
    "        s_loss, c_loss = style_content_loss(\n",
    "            style_outputs + outputs[num_style_layers:],\n",
    "            style_targets,\n",
    "            content_targets,\n",
    "            num_style_layers\n",
    "        )\n",
    "        tv_loss = total_variation_loss(image) * total_variation_weight\n",
    "        \n",
    "        total_loss = s_loss + c_loss + tv_loss\n",
    "    \n",
    "    grad = tape.gradient(total_loss, image)\n",
    "    opt.apply_gradients([(grad, image)])\n",
    "    \n",
    "    # Clipping\n",
    "    image.assign(tf.clip_by_value(image, -150.0, 150.0))\n",
    "    \n",
    "    return total_loss, s_loss, c_loss, tv_loss\n",
    "\n",
    "# Training Loop\n",
    "print(\"\\nStarte Style Transfer...\")\n",
    "steps_per_iteration = 100\n",
    "\n",
    "for i in range(iterations):\n",
    "    print(f'\\n=== Iteration {i+1}/{iterations} ===')\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for step in range(steps_per_iteration):\n",
    "        total_loss, s_loss, c_loss, tv_loss = train_step(generated_image)\n",
    "        \n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step {step:3d}: Loss={float(total_loss):12.4e} \"\n",
    "                  f\"(style={float(s_loss):10.4e}, content={float(c_loss):10.4e}, tv={float(tv_loss):10.4e})\")\n",
    "    \n",
    "    # Speichere aktuelles Bild\n",
    "    img = deprocess_image(generated_image)\n",
    "    fname = f'{result_prefix}at_iteration_{i+1}.png'\n",
    "    save_img(fname, img)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f'✓ Image saved as {fname}')\n",
    "    print(f'✓ Iteration completed in {end_time - start_time:.1f}s')\n",
    "\n",
    "print(\"\\n✓ Style Transfer abgeschlossen!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
