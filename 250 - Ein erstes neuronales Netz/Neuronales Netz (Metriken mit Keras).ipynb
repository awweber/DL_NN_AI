{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorstellung: MNIST-Daten!\n",
    "# http://yann.lecun.com/exdb/mnist/\n",
    "# FashionMNIST: https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "def open_images(filename):\n",
    "    with gzip.open(filename, \"rb\") as file:\n",
    "        data = file.read()\n",
    "        return np.frombuffer(data, dtype=np.uint8, offset=16)\\\n",
    "            .reshape(-1, 28, 28)\\\n",
    "            .astype(np.float32)\n",
    "\n",
    "\n",
    "def open_labels(filename):\n",
    "    with gzip.open(filename, \"rb\") as file:\n",
    "        data = file.read()\n",
    "        return np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "    \n",
    "X_train = open_images(\"../data/fashion/train-images-idx3-ubyte.gz\")\n",
    "y_train = open_labels(\"../data/fashion/train-labels-idx1-ubyte.gz\")\n",
    "\n",
    "y_train = y_train == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 15:41:00.509236: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-30 15:41:00.651125: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-30 15:41:11.394082: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/ml/lib/python3.11/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-09-30 15:41:17.885425: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, activation=\"sigmoid\", input_shape=(784,)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.8873 - loss: 0.2829\n",
      "Epoch 2/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9222 - loss: 0.1910\n",
      "Epoch 3/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9395 - loss: 0.1669\n",
      "Epoch 4/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9459 - loss: 0.1535\n",
      "Epoch 5/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9500 - loss: 0.1439\n",
      "Epoch 6/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9514 - loss: 0.1364\n",
      "Epoch 7/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9525 - loss: 0.1310\n",
      "Epoch 8/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9533 - loss: 0.1274\n",
      "Epoch 9/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9539 - loss: 0.1242\n",
      "Epoch 10/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9540 - loss: 0.1217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb8e21390d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train.reshape(60000, 784),\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.9539 - loss: 0.1203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12027911096811295, 0.9538999795913696]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train.reshape(60000, 784), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "model.evaluate(\n",
      "    x=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    y=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    batch_size=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    verbose=\u001b[33m'auto'\u001b[39m,\n",
      "    sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    steps=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    callbacks=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    return_dict=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    **kwargs,\n",
      ")\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Returns the loss value & metrics values for the model in test mode.\n",
      "\n",
      "Computation is done in batches (see the `batch_size` arg.)\n",
      "\n",
      "Args:\n",
      "    x: Input data. It can be:\n",
      "        - A NumPy array (or array-like), or a list of arrays\n",
      "        (in case the model has multiple inputs).\n",
      "        - A backend-native tensor, or a list of tensors\n",
      "        (in case the model has multiple inputs).\n",
      "        - A dict mapping input names to the corresponding array/tensors,\n",
      "        if the model has named inputs.\n",
      "        - A `keras.utils.PyDataset` returning `(inputs, targets)` or\n",
      "        `(inputs, targets, sample_weights)`.\n",
      "        - A `tf.data.Dataset` yielding `(inputs, targets)` or\n",
      "        `(inputs, targets, sample_weights)`.\n",
      "        - A `torch.utils.data.DataLoader` yielding `(inputs, targets)`\n",
      "        or `(inputs, targets, sample_weights)`.\n",
      "        - A Python generator function yielding `(inputs, targets)` or\n",
      "        `(inputs, targets, sample_weights)`.\n",
      "    y: Target data. Like the input data `x`, it can be either NumPy\n",
      "        array(s) or backend-native tensor(s). If `x` is a\n",
      "        `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "        `torch.utils.data.DataLoader` or a Python generator function,\n",
      "        `y` should not be specified since targets will be obtained from\n",
      "        `x`.\n",
      "    batch_size: Integer or `None`.\n",
      "        Number of samples per batch of computation.\n",
      "        If unspecified, `batch_size` will default to 32.\n",
      "        Do not specify the `batch_size` if your input data `x` is a\n",
      "        `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "        `torch.utils.data.DataLoader` or Python generator function\n",
      "        since they generate batches.\n",
      "    verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
      "        0 = silent, 1 = progress bar, 2 = single line.\n",
      "        `\"auto\"` becomes 1 for most cases.\n",
      "        Note that the progress bar is not\n",
      "        particularly useful when logged to a file, so `verbose=2` is\n",
      "        recommended when not running interactively\n",
      "        (e.g. in a production environment). Defaults to `\"auto\"`.\n",
      "    sample_weight: Optional NumPy array or tensor of weights for\n",
      "        the training samples, used for weighting the loss function\n",
      "        (during training only). You can either pass a flat (1D)\n",
      "        NumPy array or tensor with the same length as the input samples\n",
      "        (1:1 mapping between weights and samples), or in the case of\n",
      "        temporal data, you can pass a 2D NumPy array or tensor with\n",
      "        shape `(samples, sequence_length)` to apply a different weight\n",
      "        to every timestep of every sample.\n",
      "        This argument is not supported when `x` is a\n",
      "        `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "        `torch.utils.data.DataLoader` or Python generator function.\n",
      "        Instead, provide `sample_weights` as the third element of `x`.\n",
      "        Note that sample weighting does not apply to metrics specified\n",
      "        via the `metrics` argument in `compile()`. To apply sample\n",
      "        weighting to your metrics, you can specify them via the\n",
      "        `weighted_metrics` in `compile()` instead.\n",
      "    steps: Integer or `None`.\n",
      "        Total number of steps (batches of samples) to draw before\n",
      "        declaring the evaluation round finished. If `steps` is `None`,\n",
      "        it will run until `x` is exhausted. In the case of an infinitely\n",
      "        repeating dataset, it will run indefinitely.\n",
      "    callbacks: List of `keras.callbacks.Callback` instances.\n",
      "        List of callbacks to apply during evaluation.\n",
      "    return_dict: If `True`, loss and metric results are returned as a\n",
      "        dict, with each key being the name of the metric.\n",
      "        If `False`, they are returned as a list.\n",
      "\n",
      "Returns:\n",
      "    Scalar test loss (if the model has a single output and no metrics)\n",
      "    or list of scalars (if the model has multiple outputs\n",
      "    and/or metrics). The attribute `model.metrics_names` will give you\n",
      "    the display labels for the scalar outputs.\n",
      "\u001b[31mFile:\u001b[39m      ~/anaconda3/envs/ml/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\n",
      "\u001b[31mType:\u001b[39m      method"
     ]
    }
   ],
   "source": [
    "model.evaluate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'compile_metrics']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
