{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textgenerierung mit LSTM und Embedding-Layer (Kafka/Goethe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose between 'Die Verwandulung' und 'Faust'\n",
    "book = \"goethe\"  # Options: \"kafka\" or \"goethe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if book == \"kafka\":\n",
    "    with open(\"verwandlung.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        contents = file.read()\n",
    "    contents = \"\\n\".join(contents.split(\"\\n\")[59:1952])\n",
    "elif book == \"goethe\":\n",
    "    with open(\"faust.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        contents = file.read()\n",
    "    contents = contents.split(\"\\n\")[52:7052]\n",
    "    contents = [line.strip() for line in contents]\n",
    "    contents = \"\\n\".join(contents)\n",
    "    contents = contents.replace(\"\\n\", \" \\\\n \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden des Mappings und Transformation der Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "tokens = nltk.word_tokenize(contents)\n",
    "\n",
    "with open(\"word_to_int.pickle\", \"rb\") as file:\n",
    "    word_to_int = pickle.load(file)\n",
    "    \n",
    "with open(\"int_to_word.pickle\", \"rb\") as file:\n",
    "    int_to_word = pickle.load(file)\n",
    "\n",
    "tokens_transformed = [word_to_int[word] for word in tokens if word in word_to_int]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden des trainierten Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "if book == \"kafka\":\n",
    "    model = load_model(\"verwandlung.keras\")\n",
    "    #model = load_model(\"verwandlung.model\")\n",
    "elif book == \"goethe\":\n",
    "    model = load_model(\"faust.keras\")\n",
    "    #model = load_model(\"faust.model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausgabe des Start-Satzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lebens Lauf , \n",
      " Und nennt die , die , um schöne Stunden \n",
      " Vom Glück , vor mir . \n",
      " \n",
      " Sie hören nicht die , \n",
      " Die , denen ich die ersten ; \n",
      " ist das , \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = tokens_transformed[100:140]\n",
    "\n",
    "if book=='kafka':\n",
    "    print(\" \".join([int_to_word[token] for token in sentence]))\n",
    "elif book=='goethe':\n",
    "    print(\" \".join([int_to_word[token] for token in sentence]).replace(\"\\\\n\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prädiktion des nächsten Wortes in einem Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sie und schweben , \n",
      " Und ich um all bin \n",
      " Und sich mehr getan , \n",
      " Um , was vor der ! \n",
      " \n",
      " FAUST : \n",
      " meinen hohe \n",
      " \n",
      " FAUST : \n",
      " will da doch lange , \n",
      " hast ihr einen , \n",
      " Die 's die Tag der . \n",
      " \n",
      " FAUST : \n",
      " Und , was , der Herr , die Mut , \n",
      " Bin 's je , \n",
      " Für gute . \n",
      " \n",
      " MARTHE : \n",
      " Laß ihr so fort ! '' \n",
      " \n",
      " DER HERR : \n",
      " \n",
      " MARGARETE : \n",
      " Der Teufel her , ich gern die \n",
      " Und besser vorbei auf , \n",
      " all , \n",
      " Als davon in meiner Brust zurück . \n",
      " \n",
      " FAUST : \n",
      " mehr ? \n",
      " \n",
      " SCHÜLER : \n",
      " Ihr sie die , \n",
      " Nun , der , \n",
      " Und hier gewiß vor diesem Stein . \n",
      " Was wenn Ihr unten aufs haben getan , \n",
      " Du mich nicht fehlt . \n",
      " Doch gibt die ? \n",
      " War das , in \n",
      " Sich . \n",
      " \n",
      " FROSCH : \n",
      " er wird 's der , es mich ! \n",
      " O mag es so ein Welt führen ! \n",
      " Wir auf auch sein \n",
      " Mein wird fehlt ein ; \n",
      " So diese meiner , \n",
      " Die Hand so , uns auf der Welt . \n",
      " \n",
      " MARTHE ( von , am Garten läuft : \n",
      " Gib fort , ist ! \n",
      " Der ! armen ! \n",
      " Weh , der sich meinen sehn . \n",
      " \n",
      " MEPHISTOPHELES : \n",
      " es frisch ! ich recht , `` doch ihr meinen mir , \n",
      " Und von der Leib . \n",
      " Sie mich nicht gar Staub mir \n",
      " Aus einem Kind . \n",
      " \n",
      " \n",
      " \n",
      " ! \n",
      " Von dem Volk , "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sentence = np.array(tokens_transformed[100:140])\n",
    "\n",
    "for i in range(0, 300):\n",
    "    prediction = model.predict(sentence.reshape(1, 40), verbose=0)\n",
    "    \n",
    "    # word = np.argmax(prediction[0])\n",
    "    word = np.random.choice(len(int_to_word), p=prediction[0])\n",
    "    print(int_to_word[word].replace(\"\\\\n\", \"\\n\"), end=\" \")\n",
    "    \n",
    "    sentence = np.append(sentence[1:], [word])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
